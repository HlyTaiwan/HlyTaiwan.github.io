{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawler(url):\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        soup.find_all('div', class_ = 'team home')[2]\n",
    "    except IndexError:\n",
    "            time.sleep(20)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    driver.quit()\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_box_score, date, away_team, win_team = [], [], [], []\n",
    "with open('C:/Users/葉/Desktop/台大經濟所/資料科學與社會研究/2023樂天.txt', 'r', encoding=\"utf-8\") as file:\n",
    "  soup = BeautifulSoup(file, 'html.parser')\n",
    "  tr = soup.find('div', class_ = 'RecordTable').find_all('tr')\n",
    "  for td in tr[1:]:\n",
    "    for_url = td.find('td', class_ = 'sticky num')\n",
    "    href = str(for_url.find('a')).split('\"')[1].replace('amp;', '')\n",
    "    for_url_str = f\"https://www.cpbl.com.tw{href}\"\n",
    "    url_box_score.append(for_url_str)\n",
    "    \n",
    "    for_date = td.find_all('td', class_ = 'num')[1].text\n",
    "    date.append(for_date)\n",
    "\n",
    "    for_away = td.find_all('td')[4].text\n",
    "    away_team.append(for_away)\n",
    "\n",
    "    for_wlt = td.find_all('td')[8].text\n",
    "    win_team.append(for_wlt)\n",
    "\n",
    "with open('C:/Users/葉/Desktop/台大經濟所/資料科學與社會研究/2022樂天.txt', 'r', encoding=\"utf-8\") as file:\n",
    "  soup = BeautifulSoup(file, 'html.parser')\n",
    "  tr = soup.find('div', class_ = 'RecordTable').find_all('tr')\n",
    "  for td in tr[1:]:\n",
    "    for_url = td.find('td', class_ = 'sticky num')\n",
    "    href = str(for_url.find('a')).split('\"')[1].replace('amp;', '')\n",
    "    for_url_str = f\"https://www.cpbl.com.tw{href}\"\n",
    "    url_box_score.append(for_url_str)\n",
    "\n",
    "    for_date = td.find_all('td', class_ = 'num')[1].text\n",
    "    date.append(for_date)\n",
    "\n",
    "    for_away = td.find_all('td')[4].text\n",
    "    away_team.append(for_away)\n",
    "\n",
    "    for_wlt = td.find_all('td')[8].text\n",
    "    win_team.append(for_wlt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_l_t, fans, = [], []\n",
    "for row in url_box_score[52:]:\n",
    "  soup = crawler(row)\n",
    "  try:\n",
    "    for_wlt = soup.find_all('div', class_ = 'team home')[2].find('div', class_ = 'w-l-t').text\n",
    "  except IndexError:\n",
    "    for_wlt = soup.find_all('div', class_ = 'team home')[1].find('div', class_ = 'w-l-t').text\n",
    "  w_l_t.append(for_wlt)\n",
    "\n",
    "  for_fans = soup.find_all('div', class_ = 'GameNote')[1].find_all('li')[1].text.strip('觀眾')\n",
    "  fans.append(for_fans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = zip(url_box_score, date, away_team, win_team)\n",
    "df = pd.DataFrame(data, columns=['url_box_score', 'date', 'away_team', 'win_team'])\n",
    "df.to_csv('not_all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = zip(w_l_t, fans)\n",
    "df2 = pd.DataFrame(data2, columns = ['w_l_t', 'fans'])\n",
    "df2.to_csv('not_all_data3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "以下是測試用code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28W-25L',\n",
       " '26W-24L',\n",
       " '25W-24L',\n",
       " '25W-23L',\n",
       " '23W-21L',\n",
       " '23W-20L',\n",
       " '19W-17L',\n",
       " '18W-17L',\n",
       " '18W-16L']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_l_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5114', '10502']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_test = 'https://www.cpbl.com.tw/box?KindCode=A&Year=2023&GameSno=238'\n",
    "soup_test= crawler(url_test)\n",
    "wlt_test = soup_test.find_all('div', class_ = 'team home')[2].find('div', class_ = 'w-l-t').text\n",
    "fans_test = soup_test.find_all('div', class_ = 'GameNote')[1].find_all('li')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6142'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div', class_ = 'GameNote')[1].find_all('li')[1].text.strip('觀眾')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'觀眾3861'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fans_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
